{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "root_dir = subprocess.check_output('git rev-parse --show-toplevel'.split()).decode('utf-8').strip()\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from datahandler.DataHandler import DataHandler\n",
    "\n",
    "matches_file_path = os.path.join(root_dir, 'data/mdr/matches_mdr.csv')\n",
    "actual_matches = pd.read_csv(matches_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = DataHandler(\"mdr\")\n",
    "easy_articles = dh.get_all('easy')\n",
    "hard_articles = dh.get_all('hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_articles = pd.concat([easy_articles['text'], hard_articles['text']])\n",
    "\n",
    "# Vectorize the text using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_articles)\n",
    "\n",
    "# Apply NMF for topic modeling\n",
    "nmf = NMF(n_components=10, random_state=1)\n",
    "nmf_features = nmf.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Normalize the NMF features\n",
    "nmf_features = normalize(nmf_features)\n",
    "\n",
    "# Separate the transformed features back into easy and hard sets\n",
    "easy_features = nmf_features[:len(easy_articles)]\n",
    "hard_features = nmf_features[len(easy_articles):]\n",
    "\n",
    "# Compute cosine similarity between easy and hard articles\n",
    "similarity_matrix = cosine_similarity(easy_features, hard_features)\n",
    "\n",
    "# Find the best matches\n",
    "matches = similarity_matrix.argmax(axis=1)\n",
    "\n",
    "# Extract URLs for matched articles\n",
    "easy_urls = easy_articles['url'].apply(lambda url: dh.search_by(\"easy\", \"url\", url))\n",
    "hard_urls = hard_articles.iloc[matches]['url'].apply(lambda url: dh.search_by(\"hard\", \"url\", url))\n",
    "\n",
    "# Create a DataFrame with the matches\n",
    "matches_df = pd.DataFrame({\n",
    "    'easy': easy_urls,\n",
    "    'hard': hard_urls\n",
    "})\n",
    "\n",
    "# Save the matches to a CSV file\n",
    "matches_df.to_csv('matched_articles.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
